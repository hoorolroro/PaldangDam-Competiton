{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jnRaRTmfQAj1"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from keras.layers import *\n","from keras.models import *\n","from keras.utils import *\n","from sklearn.preprocessing import *\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import RobustScaler"]},{"cell_type":"code","source":["X = pd.read_csv('X_train.csv', encoding='cp949')\n","y = pd.read_csv('y_train.csv', encoding='cp949')\n","\n","#불필요한 칼럼 삭제\n","X2 = X.drop('년월일시분', axis = 1)"],"metadata":{"id":"kedr2J6dUOie"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"9YVPzJv-fZuM","executionInfo":{"status":"ok","timestamp":1661601676464,"user_tz":-540,"elapsed":10,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"253ff2cf-c4ce-4d78-aebb-95a0c2a06ae8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        청담대교 수위 (단위: cm)  한강대교 수위 (단위: cm)  행주대교 수위 (단위: cm)\n","0                  310.7             290.0             275.3\n","1                  314.7             290.0             275.3\n","2                  313.7             290.0             275.3\n","3                  311.7             290.0             276.3\n","4                  311.7             291.0             277.3\n","...                  ...               ...               ...\n","210669             281.7             278.0             271.3\n","210670             279.7             278.0             272.3\n","210671             278.7             277.0             272.3\n","210672             277.7             276.0             271.3\n","210673             278.7             275.0             270.3\n","\n","[210674 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-92d76310-d0f9-41e2-8b25-4c7fc3292dcd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>청담대교 수위 (단위: cm)</th>\n","      <th>한강대교 수위 (단위: cm)</th>\n","      <th>행주대교 수위 (단위: cm)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>310.7</td>\n","      <td>290.0</td>\n","      <td>275.3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>314.7</td>\n","      <td>290.0</td>\n","      <td>275.3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>313.7</td>\n","      <td>290.0</td>\n","      <td>275.3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>311.7</td>\n","      <td>290.0</td>\n","      <td>276.3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>311.7</td>\n","      <td>291.0</td>\n","      <td>277.3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>210669</th>\n","      <td>281.7</td>\n","      <td>278.0</td>\n","      <td>271.3</td>\n","    </tr>\n","    <tr>\n","      <th>210670</th>\n","      <td>279.7</td>\n","      <td>278.0</td>\n","      <td>272.3</td>\n","    </tr>\n","    <tr>\n","      <th>210671</th>\n","      <td>278.7</td>\n","      <td>277.0</td>\n","      <td>272.3</td>\n","    </tr>\n","    <tr>\n","      <th>210672</th>\n","      <td>277.7</td>\n","      <td>276.0</td>\n","      <td>271.3</td>\n","    </tr>\n","    <tr>\n","      <th>210673</th>\n","      <td>278.7</td>\n","      <td>275.0</td>\n","      <td>270.3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>210674 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92d76310-d0f9-41e2-8b25-4c7fc3292dcd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-92d76310-d0f9-41e2-8b25-4c7fc3292dcd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-92d76310-d0f9-41e2-8b25-4c7fc3292dcd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# test = pd.read_csv('X_test.csv', encoding='cp949')\n","# test.isnull().sum()"],"metadata":{"id":"uPU1JkBL5jZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size = 0.2, random_state = 1234)"],"metadata":{"id":"vrbQXDHd3KtG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(X_train)"],"metadata":{"id":"cexrZPTn3ek3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661601686476,"user_tz":-540,"elapsed":6,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"b9aca697-c996-42b7-d380-ebd3bd9b50a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["X_train = np.asarray(X_train.values.tolist(), dtype=np.float64)\n","X_test = np.asarray(X_test.values.tolist(), dtype=np.float64)\n","print(X_train.shape, X_test.shape)"],"metadata":{"id":"x1TjPQLAUOgW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661612900425,"user_tz":-540,"elapsed":2017,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"c0a94511-be4d-484b-9c5e-29c3cbe1c4b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(168539, 14) (42135, 14)\n"]}]},{"cell_type":"code","source":["y_train = np.array(y_train)\n","y_test = np.array(y_test)\n","print(y_train.shape, y_test.shape)"],"metadata":{"id":"Ij8sDoW8VmzF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661612902198,"user_tz":-540,"elapsed":7,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"072b9378-344c-4344-bc65-4953f5c4a436"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(168539, 3) (42135, 3)\n"]}]},{"cell_type":"code","source":["y_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUwy1TEit1Vo","executionInfo":{"status":"ok","timestamp":1661601688141,"user_tz":-540,"elapsed":6,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"02e24409-ce95-4141-936e-609483ac021f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[321.7, 313. , 301.3],\n","       [291.7, 279. , 270.3],\n","       [307.7, 292. , 281.3],\n","       ...,\n","       [294.7, 285. , 276.3],\n","       [289.7, 276. , 263.3],\n","       [287.7, 284. , 270.3]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["MinMaxScaler 후 모델링 엄격한 검증을 위해서 트레인 셋만 스케일링 해준다."],"metadata":{"id":"oanolfpUKfwG"}},{"cell_type":"code","source":["scaler = MinMaxScaler()\n","X_train = scaler.fit_transform(X_train)\n","y_train = scaler.fit_transform(y_train)"],"metadata":{"id":"N8s5K2CWKjOU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["다시 3차원으로 바꿔줘서 LSTM 모델로 넣어준다."],"metadata":{"id":"BV-x64-YLcv2"}},{"cell_type":"code","source":["X_train = X_train.reshape(-1, 1, 14)\n","X_test = X_test.reshape(-1, 1, 14)\n","\n","y_train = y_train.reshape(-1, 1, 3)\n","y_test = y_test.reshape(-1, 1, 3)\n","\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"metadata":{"id":"i_LRXFTaUOb7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661601732767,"user_tz":-540,"elapsed":509,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"6bb108d8-2629-43ed-f760-4d7838e13ae0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(168539, 1, 14) (42135, 1, 14) (168539, 1, 3) (42135, 1, 3)\n"]}]},{"cell_type":"code","source":["y_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Ti48o5WthxH","executionInfo":{"status":"ok","timestamp":1661601736932,"user_tz":-540,"elapsed":428,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"e4bca2c4-f33b-4738-9a2f-72c03e16eee8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0.375     , 0.39215686, 0.46153846]],\n","\n","       [[0.17763158, 0.16993464, 0.22307692]],\n","\n","       [[0.28289474, 0.25490196, 0.30769231]],\n","\n","       ...,\n","\n","       [[0.19736842, 0.20915033, 0.26923077]],\n","\n","       [[0.16447368, 0.1503268 , 0.16923077]],\n","\n","       [[0.15131579, 0.20261438, 0.22307692]]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["model = Sequential()\n","model.add(LSTM(256, input_shape=(1, 14,), return_sequences=True, activation='relu'))\n","#model.add(Dense(5))\n","model.add(LSTM(256, return_sequences=True, activation='relu'))\n","model.add(Dense(128))\n","model.add(Dense(64))\n","model.add(Dense(3))\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.00008)\n","model.compile(loss='mse', optimizer=optimizer, metrics=['acc'])\n","early_stop = EarlyStopping(monitor='val_loss', patience=10)\n","model.summary()"],"metadata":{"id":"O_sKctljUOZl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661612910088,"user_tz":-540,"elapsed":1037,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"1bd40edb-5240-4dff-8f02-0210b794e409"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 1, 256)            277504    \n","                                                                 \n"," lstm_1 (LSTM)               (None, 1, 256)            525312    \n","                                                                 \n"," dense (Dense)               (None, 1, 128)            32896     \n","                                                                 \n"," dense_1 (Dense)             (None, 1, 64)             8256      \n","                                                                 \n"," dense_2 (Dense)             (None, 1, 3)              195       \n","                                                                 \n","=================================================================\n","Total params: 844,163\n","Trainable params: 844,163\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["print(X_train.shape)\n","hist = model.fit(X_train, y_train, epochs=100, batch_size=24, validation_split=0.2,callbacks=[early_stop])"],"metadata":{"id":"Xg3npUYcV65S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661606836665,"user_tz":-540,"elapsed":5081270,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"69f47af4-9d09-43c3-9a69-7e3a7b1bf581"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(168539, 1, 14)\n","Epoch 1/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0025 - acc: 0.9183 - val_loss: 2.8229e-04 - val_acc: 0.9736\n","Epoch 2/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 2.6433e-04 - acc: 0.9747 - val_loss: 2.4492e-04 - val_acc: 0.9810\n","Epoch 3/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 2.4326e-04 - acc: 0.9757 - val_loss: 2.3537e-04 - val_acc: 0.9791\n","Epoch 4/100\n","5618/5618 [==============================] - 79s 14ms/step - loss: 2.2652e-04 - acc: 0.9751 - val_loss: 2.2153e-04 - val_acc: 0.9701\n","Epoch 5/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 2.1400e-04 - acc: 0.9765 - val_loss: 2.0642e-04 - val_acc: 0.9808\n","Epoch 6/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 2.0792e-04 - acc: 0.9774 - val_loss: 2.0894e-04 - val_acc: 0.9790\n","Epoch 7/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 2.0479e-04 - acc: 0.9771 - val_loss: 1.9543e-04 - val_acc: 0.9794\n","Epoch 8/100\n","5618/5618 [==============================] - 79s 14ms/step - loss: 2.0226e-04 - acc: 0.9772 - val_loss: 1.9388e-04 - val_acc: 0.9824\n","Epoch 9/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 2.0107e-04 - acc: 0.9773 - val_loss: 1.9763e-04 - val_acc: 0.9820\n","Epoch 10/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.9939e-04 - acc: 0.9779 - val_loss: 1.9885e-04 - val_acc: 0.9808\n","Epoch 11/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 1.9839e-04 - acc: 0.9777 - val_loss: 1.9660e-04 - val_acc: 0.9790\n","Epoch 12/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 1.9693e-04 - acc: 0.9780 - val_loss: 1.9960e-04 - val_acc: 0.9816\n","Epoch 13/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.9630e-04 - acc: 0.9773 - val_loss: 1.9427e-04 - val_acc: 0.9772\n","Epoch 14/100\n","5618/5618 [==============================] - 83s 15ms/step - loss: 1.9550e-04 - acc: 0.9780 - val_loss: 2.0231e-04 - val_acc: 0.9757\n","Epoch 15/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.9443e-04 - acc: 0.9777 - val_loss: 1.8995e-04 - val_acc: 0.9803\n","Epoch 16/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 1.9356e-04 - acc: 0.9779 - val_loss: 1.8834e-04 - val_acc: 0.9733\n","Epoch 17/100\n","5618/5618 [==============================] - 79s 14ms/step - loss: 1.9269e-04 - acc: 0.9784 - val_loss: 2.0190e-04 - val_acc: 0.9808\n","Epoch 18/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.9286e-04 - acc: 0.9775 - val_loss: 1.9116e-04 - val_acc: 0.9787\n","Epoch 19/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.9141e-04 - acc: 0.9783 - val_loss: 1.9484e-04 - val_acc: 0.9821\n","Epoch 20/100\n","5618/5618 [==============================] - 79s 14ms/step - loss: 1.9129e-04 - acc: 0.9782 - val_loss: 1.8745e-04 - val_acc: 0.9796\n","Epoch 21/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.9073e-04 - acc: 0.9781 - val_loss: 1.8537e-04 - val_acc: 0.9810\n","Epoch 22/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8957e-04 - acc: 0.9785 - val_loss: 1.8841e-04 - val_acc: 0.9798\n","Epoch 23/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8913e-04 - acc: 0.9780 - val_loss: 1.9187e-04 - val_acc: 0.9803\n","Epoch 24/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 1.8871e-04 - acc: 0.9784 - val_loss: 1.9116e-04 - val_acc: 0.9788\n","Epoch 25/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 1.8790e-04 - acc: 0.9780 - val_loss: 1.8867e-04 - val_acc: 0.9818\n","Epoch 26/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8742e-04 - acc: 0.9786 - val_loss: 1.8130e-04 - val_acc: 0.9829\n","Epoch 27/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8733e-04 - acc: 0.9784 - val_loss: 1.8417e-04 - val_acc: 0.9798\n","Epoch 28/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8645e-04 - acc: 0.9785 - val_loss: 1.9145e-04 - val_acc: 0.9796\n","Epoch 29/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8622e-04 - acc: 0.9782 - val_loss: 1.8388e-04 - val_acc: 0.9796\n","Epoch 30/100\n","5618/5618 [==============================] - 83s 15ms/step - loss: 1.8560e-04 - acc: 0.9785 - val_loss: 1.8591e-04 - val_acc: 0.9813\n","Epoch 31/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8532e-04 - acc: 0.9781 - val_loss: 1.8275e-04 - val_acc: 0.9749\n","Epoch 32/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8479e-04 - acc: 0.9786 - val_loss: 1.8520e-04 - val_acc: 0.9795\n","Epoch 33/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8454e-04 - acc: 0.9785 - val_loss: 1.8165e-04 - val_acc: 0.9749\n","Epoch 34/100\n","5618/5618 [==============================] - 83s 15ms/step - loss: 1.8454e-04 - acc: 0.9784 - val_loss: 1.8034e-04 - val_acc: 0.9825\n","Epoch 35/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8341e-04 - acc: 0.9785 - val_loss: 1.8149e-04 - val_acc: 0.9796\n","Epoch 36/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8355e-04 - acc: 0.9780 - val_loss: 1.8195e-04 - val_acc: 0.9790\n","Epoch 37/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8310e-04 - acc: 0.9783 - val_loss: 1.8135e-04 - val_acc: 0.9750\n","Epoch 38/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8274e-04 - acc: 0.9783 - val_loss: 1.7929e-04 - val_acc: 0.9769\n","Epoch 39/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8260e-04 - acc: 0.9775 - val_loss: 1.7967e-04 - val_acc: 0.9785\n","Epoch 40/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8172e-04 - acc: 0.9786 - val_loss: 1.7781e-04 - val_acc: 0.9818\n","Epoch 41/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8154e-04 - acc: 0.9785 - val_loss: 1.8121e-04 - val_acc: 0.9815\n","Epoch 42/100\n","5618/5618 [==============================] - 79s 14ms/step - loss: 1.8132e-04 - acc: 0.9783 - val_loss: 1.9220e-04 - val_acc: 0.9719\n","Epoch 43/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8099e-04 - acc: 0.9784 - val_loss: 1.7880e-04 - val_acc: 0.9821\n","Epoch 44/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8105e-04 - acc: 0.9782 - val_loss: 1.7701e-04 - val_acc: 0.9780\n","Epoch 45/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.8047e-04 - acc: 0.9784 - val_loss: 1.8076e-04 - val_acc: 0.9728\n","Epoch 46/100\n","5618/5618 [==============================] - 81s 15ms/step - loss: 1.7991e-04 - acc: 0.9785 - val_loss: 1.9887e-04 - val_acc: 0.9827\n","Epoch 47/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.8007e-04 - acc: 0.9785 - val_loss: 1.8466e-04 - val_acc: 0.9834\n","Epoch 48/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.7968e-04 - acc: 0.9782 - val_loss: 1.8926e-04 - val_acc: 0.9802\n","Epoch 49/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 1.7914e-04 - acc: 0.9786 - val_loss: 1.8272e-04 - val_acc: 0.9807\n","Epoch 50/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 1.7936e-04 - acc: 0.9787 - val_loss: 1.8901e-04 - val_acc: 0.9731\n","Epoch 51/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.7882e-04 - acc: 0.9786 - val_loss: 1.7859e-04 - val_acc: 0.9826\n","Epoch 52/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 1.7846e-04 - acc: 0.9788 - val_loss: 1.7760e-04 - val_acc: 0.9815\n","Epoch 53/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 1.7791e-04 - acc: 0.9788 - val_loss: 1.7451e-04 - val_acc: 0.9802\n","Epoch 54/100\n","5618/5618 [==============================] - 83s 15ms/step - loss: 1.7802e-04 - acc: 0.9787 - val_loss: 1.7660e-04 - val_acc: 0.9800\n","Epoch 55/100\n","5618/5618 [==============================] - 83s 15ms/step - loss: 1.7756e-04 - acc: 0.9789 - val_loss: 1.7732e-04 - val_acc: 0.9826\n","Epoch 56/100\n","5618/5618 [==============================] - 83s 15ms/step - loss: 1.7722e-04 - acc: 0.9789 - val_loss: 1.7781e-04 - val_acc: 0.9823\n","Epoch 57/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 1.7729e-04 - acc: 0.9791 - val_loss: 1.8156e-04 - val_acc: 0.9791\n","Epoch 58/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 1.7705e-04 - acc: 0.9787 - val_loss: 1.8135e-04 - val_acc: 0.9772\n","Epoch 59/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.7680e-04 - acc: 0.9787 - val_loss: 1.8517e-04 - val_acc: 0.9793\n","Epoch 60/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.7605e-04 - acc: 0.9787 - val_loss: 1.7772e-04 - val_acc: 0.9770\n","Epoch 61/100\n","5618/5618 [==============================] - 84s 15ms/step - loss: 1.7617e-04 - acc: 0.9787 - val_loss: 1.7587e-04 - val_acc: 0.9820\n","Epoch 62/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 1.7576e-04 - acc: 0.9788 - val_loss: 1.7624e-04 - val_acc: 0.9788\n","Epoch 63/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 1.7547e-04 - acc: 0.9789 - val_loss: 1.7719e-04 - val_acc: 0.9818\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","y_pred = model.predict(X_test)\n","print(type(y_pred))\n","y_pred = y_pred.reshape(-1, 3)\n","y_test = y_test.reshape(-1, 3)\n","\n","# # Linear Regression(선형회귀) 사용\n","\n","# lr = LinearRegression()\n","\n","# lr.fit(X_train, y_train)\n","\n","# pred = lr.predict(X_test)\n","\n","# print('r2 : ', r2_score(y_test, y_pred)) #결정계수\n","print('mse : ', mean_squared_error(y_test, y_pred)) # mse\n","print('rmse : ', np.sqrt(mean_squared_error(y_test, y_pred)))\n","\n","# plt.scatter(y_test, pred)"],"metadata":{"id":"C4XAvRCdV-xw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661606891800,"user_tz":-540,"elapsed":10809,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"7a56e118-8aaa-47cd-ad03-bdfa7e29d7f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","mse :  161174.82164986964\n","rmse :  401.46584119931003\n"]}]},{"cell_type":"markdown","source":["1.MinMaxScale은 전혀 효과가 없었다. 여기서 스케일링은 트레인셋만 진행하였다. (왜냐면 우리가 공모전의 정답지를 맞춰야할 입장이기 때문에, 튜토리얼이나 예제문제처럼 테스트셋을 minmaxScale하거나 트레인셋의 평균 분산값으로 Normalize할 수 없기 때문이다.) y-target 값은 0과1 사이에 있는 값이 아니기 때문에, minmaxscale로는 부적절하다."],"metadata":{"id":"jF3si9JxhzVN"}},{"cell_type":"code","source":["# y_pred = model.predict(X_test)\n","np.isnan(y_pred).sum()"],"metadata":{"id":"QTpxqKhmxaiV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661315071836,"user_tz":-540,"elapsed":27,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"710f5dfa-4971-4764-ea67-2de7a43e71e4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["y_pred"],"metadata":{"id":"pyU2CCb1ydBq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661315071836,"user_tz":-540,"elapsed":24,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"6fcf247c-ce2b-4bc3-d01b-f76c715314ac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[274.8823 , 267.65076, 274.02533],\n","       [299.50684, 280.30743, 258.90125],\n","       [356.38452, 340.9192 , 324.48538],\n","       ...,\n","       [341.13202, 327.95087, 314.27872],\n","       [296.8855 , 284.52847, 278.2618 ],\n","       [292.81555, 279.58298, 272.17087]], dtype=float32)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["y_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YZMm8PXnwrO","executionInfo":{"status":"ok","timestamp":1661315071837,"user_tz":-540,"elapsed":23,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"7f8bbadd-e4fa-4429-beac-120eb66d2536"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[276.7, 273. , 276.3],\n","       [299.7, 276. , 259.3],\n","       [357.7, 341. , 326.3],\n","       ...,\n","       [342.7, 335. , 316.3],\n","       [298.7, 284. , 280.3],\n","       [294.7, 278. , 274.3]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["zdef plot_history(hist):\n","    for key, values in hist.items():\n","        plt.plot(values)\n","        plt.title(key)\n","        plt.xlabel('epoch')\n","        plt.show()\n","\n","plot_history(hist.history)"],"metadata":{"id":"VqGh7SXJnzzm","executionInfo":{"status":"error","timestamp":1661315071837,"user_tz":-540,"elapsed":21,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"3381e7e4-7e56-452b-8328-d7aec9312f7b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-e1018fcfd687>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    zdef plot_history(hist):\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"markdown","source":["LSTM 5개의 계층, Batch size 24, learning rate 0.00008에서 가장 낮은 RMSE(2.429)가 나왔습니다. 이후 파라미터 개선 및 Minmaxscaler 작업 실시 예정."],"metadata":{"id":"Nk7U-dAzXvtV"}},{"cell_type":"markdown","source":["RobustScaler로 전처리 후 모델"],"metadata":{"id":"z7_1AQ1lf3P2"}},{"cell_type":"code","source":["scaler = RobustScaler()\n","X_train = scaler.fit_transform(X_train)\n","y_train = scaler.fit_transform(y_train)"],"metadata":{"id":"9kauUv10f6hA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = X_train.reshape(-1, 1, 14)\n","X_test = X_test.reshape(-1, 1, 14)\n","\n","y_train = y_train.reshape(-1, 1, 3)\n","y_test = y_test.reshape(-1, 1, 3)\n","\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFntbv01gUv4","executionInfo":{"status":"ok","timestamp":1661612922073,"user_tz":-540,"elapsed":2,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"9da60ec5-0e51-4f73-e63d-8bf626adf4be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(168539, 1, 14) (42135, 1, 14) (168539, 1, 3) (42135, 1, 3)\n"]}]},{"cell_type":"code","source":["hist = model.fit(X_train, y_train, epochs=100, batch_size=24, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tlzsnyBAgbD4","executionInfo":{"status":"ok","timestamp":1661620807888,"user_tz":-540,"elapsed":7883748,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"ac441339-c16a-4926-f7dc-29d776f5b0ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","5618/5618 [==============================] - 82s 14ms/step - loss: 0.0250 - acc: 0.7254 - val_loss: 0.0051 - val_acc: 0.7518\n","Epoch 2/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0047 - acc: 0.7816 - val_loss: 0.0050 - val_acc: 0.7958\n","Epoch 3/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0040 - acc: 0.7956 - val_loss: 0.0037 - val_acc: 0.7997\n","Epoch 4/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0037 - acc: 0.8037 - val_loss: 0.0035 - val_acc: 0.8019\n","Epoch 5/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0035 - acc: 0.8092 - val_loss: 0.0036 - val_acc: 0.8186\n","Epoch 6/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0034 - acc: 0.8111 - val_loss: 0.0033 - val_acc: 0.8083\n","Epoch 7/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0033 - acc: 0.8137 - val_loss: 0.0032 - val_acc: 0.8131\n","Epoch 8/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0033 - acc: 0.8143 - val_loss: 0.0033 - val_acc: 0.8183\n","Epoch 9/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0033 - acc: 0.8169 - val_loss: 0.0033 - val_acc: 0.8130\n","Epoch 10/100\n","5618/5618 [==============================] - 75s 13ms/step - loss: 0.0032 - acc: 0.8178 - val_loss: 0.0032 - val_acc: 0.8068\n","Epoch 11/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0032 - acc: 0.8181 - val_loss: 0.0032 - val_acc: 0.8177\n","Epoch 12/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0031 - acc: 0.8198 - val_loss: 0.0032 - val_acc: 0.8074\n","Epoch 13/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0031 - acc: 0.8216 - val_loss: 0.0032 - val_acc: 0.8221\n","Epoch 14/100\n","5618/5618 [==============================] - 76s 13ms/step - loss: 0.0031 - acc: 0.8223 - val_loss: 0.0031 - val_acc: 0.8286\n","Epoch 15/100\n","5618/5618 [==============================] - 75s 13ms/step - loss: 0.0031 - acc: 0.8232 - val_loss: 0.0031 - val_acc: 0.8201\n","Epoch 16/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0030 - acc: 0.8249 - val_loss: 0.0031 - val_acc: 0.8195\n","Epoch 17/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0030 - acc: 0.8247 - val_loss: 0.0031 - val_acc: 0.8307\n","Epoch 18/100\n","5618/5618 [==============================] - 76s 13ms/step - loss: 0.0030 - acc: 0.8256 - val_loss: 0.0030 - val_acc: 0.8299\n","Epoch 19/100\n","5618/5618 [==============================] - 76s 14ms/step - loss: 0.0030 - acc: 0.8267 - val_loss: 0.0031 - val_acc: 0.8290\n","Epoch 20/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0029 - acc: 0.8277 - val_loss: 0.0030 - val_acc: 0.8224\n","Epoch 21/100\n","5618/5618 [==============================] - 75s 13ms/step - loss: 0.0029 - acc: 0.8281 - val_loss: 0.0030 - val_acc: 0.8324\n","Epoch 22/100\n","5618/5618 [==============================] - 76s 14ms/step - loss: 0.0029 - acc: 0.8290 - val_loss: 0.0029 - val_acc: 0.8310\n","Epoch 23/100\n","5618/5618 [==============================] - 76s 14ms/step - loss: 0.0029 - acc: 0.8290 - val_loss: 0.0030 - val_acc: 0.8209\n","Epoch 24/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0029 - acc: 0.8293 - val_loss: 0.0029 - val_acc: 0.8362\n","Epoch 25/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0029 - acc: 0.8310 - val_loss: 0.0029 - val_acc: 0.8327\n","Epoch 26/100\n","5618/5618 [==============================] - 76s 14ms/step - loss: 0.0029 - acc: 0.8311 - val_loss: 0.0030 - val_acc: 0.8209\n","Epoch 27/100\n","5618/5618 [==============================] - 76s 13ms/step - loss: 0.0028 - acc: 0.8309 - val_loss: 0.0029 - val_acc: 0.8305\n","Epoch 28/100\n","5618/5618 [==============================] - 76s 14ms/step - loss: 0.0028 - acc: 0.8316 - val_loss: 0.0029 - val_acc: 0.8300\n","Epoch 29/100\n","5618/5618 [==============================] - 76s 14ms/step - loss: 0.0028 - acc: 0.8317 - val_loss: 0.0029 - val_acc: 0.8330\n","Epoch 30/100\n","5618/5618 [==============================] - 76s 13ms/step - loss: 0.0028 - acc: 0.8326 - val_loss: 0.0029 - val_acc: 0.8270\n","Epoch 31/100\n","5618/5618 [==============================] - 76s 14ms/step - loss: 0.0028 - acc: 0.8330 - val_loss: 0.0029 - val_acc: 0.8257\n","Epoch 32/100\n","5618/5618 [==============================] - 76s 13ms/step - loss: 0.0028 - acc: 0.8330 - val_loss: 0.0029 - val_acc: 0.8329\n","Epoch 33/100\n","5618/5618 [==============================] - 75s 13ms/step - loss: 0.0028 - acc: 0.8334 - val_loss: 0.0028 - val_acc: 0.8359\n","Epoch 34/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0028 - acc: 0.8335 - val_loss: 0.0029 - val_acc: 0.8362\n","Epoch 35/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0028 - acc: 0.8337 - val_loss: 0.0029 - val_acc: 0.8339\n","Epoch 36/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0028 - acc: 0.8346 - val_loss: 0.0028 - val_acc: 0.8325\n","Epoch 37/100\n","5618/5618 [==============================] - 76s 13ms/step - loss: 0.0027 - acc: 0.8353 - val_loss: 0.0029 - val_acc: 0.8387\n","Epoch 38/100\n","5618/5618 [==============================] - 76s 13ms/step - loss: 0.0027 - acc: 0.8359 - val_loss: 0.0028 - val_acc: 0.8362\n","Epoch 39/100\n","5618/5618 [==============================] - 76s 13ms/step - loss: 0.0027 - acc: 0.8353 - val_loss: 0.0028 - val_acc: 0.8335\n","Epoch 40/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0027 - acc: 0.8353 - val_loss: 0.0028 - val_acc: 0.8308\n","Epoch 41/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0027 - acc: 0.8356 - val_loss: 0.0029 - val_acc: 0.8332\n","Epoch 42/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0027 - acc: 0.8359 - val_loss: 0.0028 - val_acc: 0.8361\n","Epoch 43/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0027 - acc: 0.8365 - val_loss: 0.0028 - val_acc: 0.8352\n","Epoch 44/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0027 - acc: 0.8368 - val_loss: 0.0028 - val_acc: 0.8348\n","Epoch 45/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0027 - acc: 0.8366 - val_loss: 0.0028 - val_acc: 0.8382\n","Epoch 46/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0027 - acc: 0.8370 - val_loss: 0.0028 - val_acc: 0.8356\n","Epoch 47/100\n","5618/5618 [==============================] - 76s 14ms/step - loss: 0.0027 - acc: 0.8374 - val_loss: 0.0028 - val_acc: 0.8334\n","Epoch 48/100\n","5618/5618 [==============================] - 77s 14ms/step - loss: 0.0027 - acc: 0.8377 - val_loss: 0.0028 - val_acc: 0.8377\n","Epoch 49/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0027 - acc: 0.8376 - val_loss: 0.0028 - val_acc: 0.8372\n","Epoch 50/100\n","5618/5618 [==============================] - 78s 14ms/step - loss: 0.0026 - acc: 0.8377 - val_loss: 0.0027 - val_acc: 0.8367\n","Epoch 51/100\n","5618/5618 [==============================] - 79s 14ms/step - loss: 0.0026 - acc: 0.8382 - val_loss: 0.0028 - val_acc: 0.8365\n","Epoch 52/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0026 - acc: 0.8387 - val_loss: 0.0028 - val_acc: 0.8338\n","Epoch 53/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0026 - acc: 0.8382 - val_loss: 0.0027 - val_acc: 0.8378\n","Epoch 54/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0026 - acc: 0.8387 - val_loss: 0.0028 - val_acc: 0.8361\n","Epoch 55/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0026 - acc: 0.8388 - val_loss: 0.0027 - val_acc: 0.8363\n","Epoch 56/100\n","5618/5618 [==============================] - 79s 14ms/step - loss: 0.0026 - acc: 0.8392 - val_loss: 0.0028 - val_acc: 0.8303\n","Epoch 57/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0026 - acc: 0.8397 - val_loss: 0.0028 - val_acc: 0.8332\n","Epoch 58/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0026 - acc: 0.8398 - val_loss: 0.0027 - val_acc: 0.8398\n","Epoch 59/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0026 - acc: 0.8410 - val_loss: 0.0028 - val_acc: 0.8311\n","Epoch 60/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0026 - acc: 0.8401 - val_loss: 0.0027 - val_acc: 0.8357\n","Epoch 61/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0026 - acc: 0.8407 - val_loss: 0.0028 - val_acc: 0.8308\n","Epoch 62/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0026 - acc: 0.8401 - val_loss: 0.0027 - val_acc: 0.8463\n","Epoch 63/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0026 - acc: 0.8414 - val_loss: 0.0028 - val_acc: 0.8430\n","Epoch 64/100\n","5618/5618 [==============================] - 81s 15ms/step - loss: 0.0026 - acc: 0.8411 - val_loss: 0.0027 - val_acc: 0.8429\n","Epoch 65/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0026 - acc: 0.8420 - val_loss: 0.0028 - val_acc: 0.8335\n","Epoch 66/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0026 - acc: 0.8422 - val_loss: 0.0027 - val_acc: 0.8416\n","Epoch 67/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0025 - acc: 0.8421 - val_loss: 0.0027 - val_acc: 0.8389\n","Epoch 68/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0025 - acc: 0.8424 - val_loss: 0.0027 - val_acc: 0.8351\n","Epoch 69/100\n","5618/5618 [==============================] - 79s 14ms/step - loss: 0.0025 - acc: 0.8414 - val_loss: 0.0027 - val_acc: 0.8351\n","Epoch 70/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0025 - acc: 0.8429 - val_loss: 0.0027 - val_acc: 0.8369\n","Epoch 71/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8427 - val_loss: 0.0027 - val_acc: 0.8424\n","Epoch 72/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0025 - acc: 0.8428 - val_loss: 0.0027 - val_acc: 0.8446\n","Epoch 73/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8442 - val_loss: 0.0027 - val_acc: 0.8429\n","Epoch 74/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0025 - acc: 0.8433 - val_loss: 0.0027 - val_acc: 0.8441\n","Epoch 75/100\n","5618/5618 [==============================] - 83s 15ms/step - loss: 0.0025 - acc: 0.8440 - val_loss: 0.0027 - val_acc: 0.8420\n","Epoch 76/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8434 - val_loss: 0.0027 - val_acc: 0.8437\n","Epoch 77/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8444 - val_loss: 0.0027 - val_acc: 0.8426\n","Epoch 78/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8450 - val_loss: 0.0027 - val_acc: 0.8454\n","Epoch 79/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8442 - val_loss: 0.0027 - val_acc: 0.8429\n","Epoch 80/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8452 - val_loss: 0.0027 - val_acc: 0.8466\n","Epoch 81/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0025 - acc: 0.8455 - val_loss: 0.0027 - val_acc: 0.8480\n","Epoch 82/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0025 - acc: 0.8457 - val_loss: 0.0027 - val_acc: 0.8351\n","Epoch 83/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8456 - val_loss: 0.0028 - val_acc: 0.8306\n","Epoch 84/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8460 - val_loss: 0.0027 - val_acc: 0.8475\n","Epoch 85/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0025 - acc: 0.8453 - val_loss: 0.0027 - val_acc: 0.8472\n","Epoch 86/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0025 - acc: 0.8459 - val_loss: 0.0026 - val_acc: 0.8401\n","Epoch 87/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0024 - acc: 0.8466 - val_loss: 0.0026 - val_acc: 0.8412\n","Epoch 88/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0024 - acc: 0.8459 - val_loss: 0.0027 - val_acc: 0.8459\n","Epoch 89/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0024 - acc: 0.8471 - val_loss: 0.0026 - val_acc: 0.8395\n","Epoch 90/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0024 - acc: 0.8468 - val_loss: 0.0026 - val_acc: 0.8403\n","Epoch 91/100\n","5618/5618 [==============================] - 82s 15ms/step - loss: 0.0024 - acc: 0.8469 - val_loss: 0.0027 - val_acc: 0.8405\n","Epoch 92/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0024 - acc: 0.8473 - val_loss: 0.0026 - val_acc: 0.8430\n","Epoch 93/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0024 - acc: 0.8472 - val_loss: 0.0027 - val_acc: 0.8331\n","Epoch 94/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0024 - acc: 0.8473 - val_loss: 0.0026 - val_acc: 0.8427\n","Epoch 95/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0024 - acc: 0.8476 - val_loss: 0.0026 - val_acc: 0.8478\n","Epoch 96/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0024 - acc: 0.8478 - val_loss: 0.0026 - val_acc: 0.8384\n","Epoch 97/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0024 - acc: 0.8476 - val_loss: 0.0026 - val_acc: 0.8415\n","Epoch 98/100\n","5618/5618 [==============================] - 80s 14ms/step - loss: 0.0024 - acc: 0.8480 - val_loss: 0.0026 - val_acc: 0.8445\n","Epoch 99/100\n","5618/5618 [==============================] - 81s 14ms/step - loss: 0.0024 - acc: 0.8484 - val_loss: 0.0026 - val_acc: 0.8442\n","Epoch 100/100\n","5618/5618 [==============================] - 79s 14ms/step - loss: 0.0024 - acc: 0.8486 - val_loss: 0.0026 - val_acc: 0.8494\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","y_pred = model.predict(X_test)\n","print(type(y_pred))\n","y_pred = y_pred.reshape(-1, 3)\n","y_test = y_test.reshape(-1, 3)\n","\n","# # Linear Regression(선형회귀) 사용\n","\n","# lr = LinearRegression()\n","\n","# lr.fit(X_train, y_train)\n","\n","# pred = lr.predict(X_test)\n","\n","# print('r2 : ', r2_score(y_test, y_pred)) #결정계수\n","print('mse : ', mean_squared_error(y_test, y_pred)) # mse\n","print('rmse : ', np.sqrt(mean_squared_error(y_test, y_pred)))\n","\n","# plt.scatter(y_test, pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7gtWyPSghR6","executionInfo":{"status":"ok","timestamp":1661620813311,"user_tz":-540,"elapsed":5436,"user":{"displayName":"Seong Min Yeo","userId":"06775264260955032192"}},"outputId":"1227885a-6a93-4ca0-80f4-f09144502bdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","mse :  254966.30366726444\n","rmse :  504.9418814747539\n"]}]},{"cell_type":"markdown","source":["결론: 그 뿐만 아니라, 머신러닝을 사용한 scale 자체가 부적절하다는게 의견입니다. 애초에 공모전 특성상 테스트셋을 건드릴 수 없어서, sklearn을 이용한 기계적인 scaling 하는거 자체가 무의미합니다. 우리가 자체적으로 전처리를 잘해서 스코어를 올리는걸 목표로 삼는게 좋다는게 의견입니다."],"metadata":{"id":"dp4mFMsChS08"}}]}